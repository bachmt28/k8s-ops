#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os, sys, re, json, csv, hashlib, time, glob, shutil, datetime, random
from typing import Tuple, Dict, List

# ---------- DEBUG ----------
DEBUG = os.environ.get("DEBUG", "0").lower() in ("1", "true", "yes")

def dbg(msg: str):
    if DEBUG:
        print(msg, flush=True)

# ---------- Utils ----------
def now_utc_iso() -> str:
    return datetime.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")

def req_id() -> str:
    rand = "".join(random.choice("0123456789abcdef") for _ in range(4))
    return f"exc-{datetime.datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}-{rand}"

def normalize_crlf(s: str) -> str:
    return s.replace("\r", "") if s else s

def strip_inline_comment(s: str) -> str:
    """Remove trailing # comment outside quotes."""
    out = []
    in_s = in_d = False
    for ch in s:
        if ch == "'" and not in_d:
            in_s = not in_s
        elif ch == '"' and not in_s:
            in_d = not in_d
        if ch == "#" and not in_s and not in_d:
            break
        out.append(ch)
    return "".join(out)

def unquote(s: str) -> str:
    s = s.strip()
    if len(s) >= 2 and ((s[0] == s[-1] == "'") or (s[0] == s[-1] == '"')):
        return s[1:-1]
    return s

def boolnorm(v: str) -> bool:
    return str(v).strip().lower() in ("true", "1", "yes", "y", "on")

def norm_date(s: str) -> str:
    s = s.strip()
    if re.fullmatch(r"\d{8}", s):        # YYYYMMDD -> YYYY-MM-DD
        return f"{s[0:4]}-{s[4:6]}-{s[6:8]}"
    return s

def sha256_hex(s: str) -> str:
    return hashlib.sha256(s.encode("utf-8")).hexdigest()

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

# ---------- Strict workload parser ----------
def parse_exec_workload_list_strict(block: str) -> Tuple[List[str], List[Tuple[int, str, str]]]:
    """
    EXEC_WORKLOAD_LIST (STRICT):
      - M·ªói d√≤ng b·∫Øt bu·ªôc c√≥ '|'
      - Cho ph√©p kho·∫£ng tr·∫Øng quanh '|'
      - V·∫ø tr√°i = namespace (kh√¥ng r·ªóng)
      - V·∫ø ph·∫£i = workload name (kh√¥ng r·ªóng) -> n·∫øu r·ªóng coi l√† l·ªói (ƒë·ªÉ tr√°nh l·ªách format)
    Tr·∫£ v·ªÅ: (list 'ns|workload' s·∫°ch), invalid_lines[(line_no, original, reason)]
    """
    cleaned = []
    invalid = []
    if not block:
        return [], invalid

    for idx, raw in enumerate(normalize_crlf(block).splitlines(), start=1):
        display = raw.rstrip("\n")
        line = strip_inline_comment(raw).strip()
        if not line:
            continue  # b·ªè d√≤ng tr·ªëng/comment
        if "|" not in line:
            invalid.append((idx, display, "missing '|' separator"))
            continue
        left, right = line.split("|", 1)
        ns = left.strip()
        wl = right.strip()
        if not ns:
            invalid.append((idx, display, "empty namespace (left side)"))
            continue
        if not wl:
            invalid.append((idx, display, "empty workload (right side)"))
            continue
        cleaned.append(f"{ns}|{wl}")
    return cleaned, invalid

# ---------- Retention ----------
def safe_path_guard(raw_root: str) -> bool:
    if not raw_root or raw_root == "/":
        dbg(f"‚ùå RAW_ROOT nguy hi·ªÉm: '{raw_root}'")
        return False
    if "/exceptions/raw" not in raw_root:
        dbg(f"‚ùå RAW_ROOT kh√¥ng h·ª£p l·ªá (y/c ch·ª©a '/exceptions/raw'): {raw_root}")
        return False
    ensure_dir(raw_root)
    return True

def retention_cleanup(raw_root: str, retain_days: int, dry_run: bool):
    dbg(f"üßπ Retention: path={raw_root}, keep {retain_days}d, dry_run={int(dry_run)}")
    lock_dir = os.path.join(raw_root, ".retention.lock")
    for _ in range(60):
        try:
            os.mkdir(lock_dir)
            break
        except FileExistsError:
            time.sleep(1)
    else:
        dbg("‚ö†Ô∏è  Retention lock timeout, skip")
        return
    try:
        cutoff = time.time() - retain_days * 86400
        patterns = ("raw-*.jsonl", "raw-*.csv", "raw-*.meta")
        victims = []
        for root, _, _ in os.walk(raw_root):
            for pat in patterns:
                for p in glob.glob(os.path.join(root, pat)):
                    try:
                        if os.path.getmtime(p) < cutoff:
                            victims.append(p)
                    except Exception:
                        pass
        if not victims:
            dbg("‚úÖ Kh√¥ng c√≥ file qu√° h·∫°n.")
            return
        dbg(f"üìÑ File qu√° h·∫°n ({len(victims)}):")
        for p in victims:
            dbg(f"  - {p}")
        if dry_run:
            dbg("üîé DRY-RUN: ch·ªâ li·ªát k√™, KH√îNG xo√°. (RETENTION_DRY_RUN=0 ƒë·ªÉ xo√° th·∫≠t)")
        else:
            for p in victims:
                try:
                    os.remove(p)
                except Exception:
                    pass
            dbg(f"üóëÔ∏è  ƒê√£ xo√° {len(victims)} file.")
    finally:
        try:
            os.rmdir(lock_dir)
        except Exception:
            pass

# ---------- Main ----------
def main():
    # === ENV & required vars ===
    RAW_ROOT = os.environ.get("RAW_ROOT", "/data/exceptions/raw")
    RETAIN_DAYS = int(os.environ.get("RETAIN_DAYS", "90"))
    RETENTION_DRY_RUN = os.environ.get("RETENTION_DRY_RUN", "0").lower() in ("1", "true", "yes")

    EXEC_ON_247   = os.environ.get("EXEC_ON_247", "false")
    EXEC_ON_OUT   = os.environ.get("EXEC_ON_OUT", "true")
    EXEC_REQUESTER = (os.environ.get("EXEC_REQUESTER") or "").strip()
    EXEC_REASON    = (os.environ.get("EXEC_REASON") or "").strip()
    EXEC_END_DATE  = (os.environ.get("EXEC_END_DATE") or "").strip()
    EXEC_WORKLOAD_LIST = os.environ.get("EXEC_WORKLOAD_LIST", "")

    # Thi·∫øu bi·∫øn b·∫Øt bu·ªôc -> fail s·ªõm (ƒë√£ ƒë∆∞·ª£c Preflight/Validator ki·ªÉm tr∆∞·ªõc, nh∆∞ng v·∫´n si·∫øt ·ªü ƒë√¢y)
    missing = []
    if not EXEC_REQUESTER: missing.append("EXEC_REQUESTER")
    if not EXEC_REASON:    missing.append("EXEC_REASON")
    if not EXEC_END_DATE:  missing.append("EXEC_END_DATE")
    if not EXEC_WORKLOAD_LIST: missing.append("EXEC_WORKLOAD_LIST")
    if missing:
        print("‚ùå Thi·∫øu bi·∫øn ENV b·∫Øt bu·ªôc: " + ", ".join(missing))
        sys.exit(1)

    # Chu·∫©n ho√° ng√†y
    end_input = EXEC_END_DATE
    end_date  = norm_date(end_input)
    if not re.fullmatch(r"\d{4}-\d{2}-\d{2}", end_date):
        print(f"‚ùå EXEC_END_DATE sai ƒë·ªãnh d·∫°ng (ch·∫•p nh·∫≠n YYYYMMDD ho·∫∑c YYYY-MM-DD): {EXEC_END_DATE}")
        sys.exit(1)

    # Parse workload list (STRICT)
    wl_lines, invalid = parse_exec_workload_list_strict(EXEC_WORKLOAD_LIST)
    if invalid:
        print("‚ùå EXEC_WORKLOAD_LIST sai format (y√™u c·∫ßu m·ªói d√≤ng: `namespace | workloadName`). L·ªói chi ti·∫øt:")
        for ln, content, why in invalid:
            print(f"  - line {ln}: {why}  ==> `{content}`")
        print("\nV√≠ d·ª• h·ª£p l·ªá:")
        print("  sb-check   | multitool")
        print("  sb-backend | workloadA\n")
        sys.exit(1)

    # Metadata Jenkins
    build_user   = os.environ.get("BUILD_USER_ID") or os.environ.get("BUILD_USER") or "unknown"
    job_name     = os.environ.get("JOB_NAME", "")
    build_url    = os.environ.get("BUILD_URL", "")
    build_number = os.environ.get("BUILD_NUMBER", "local")

    rid = req_id()
    created_at = now_utc_iso()

    # Chu·∫©n b·ªã output workspace
    out_jsonl = "exceptions_draft.jsonl"
    out_csv   = "exceptions_draft.csv"
    with open(out_jsonl, "w", encoding="utf-8") as fj, \
         open(out_csv, "w", newline="", encoding="utf-8") as fc:

        cw = csv.writer(fc)
        cw.writerow([
            "req_id","seq","ns","workload","on_exeption_247","on_exeption_out_worktime",
            "requester","reason","end_date","end_input","created_at","created_by",
            "source_job","source_build","status","hash"
        ])

        seq = 0
        for raw in wl_lines:
            ns, wl = [p.strip() for p in raw.split("|", 1)]
            # Si·∫øt th√™m m·ªôt l·ªõp an to√†n (kh√¥ng th·ª´a)
            if not ns or not wl:
                continue
            seq += 1
            ex247 = boolnorm(EXEC_ON_247)
            exow  = boolnorm(EXEC_ON_OUT)
            h = sha256_hex(f"{ns}|{wl}|{end_date}|{ex247}|{exow}|{EXEC_REQUESTER}|{EXEC_REASON}")

            rec = {
                "req_id": rid, "seq": seq, "ns": ns, "workload": wl,
                "on_exeption_247": ex247, "on_exeption_out_worktime": exow,
                "requester": EXEC_REQUESTER, "reason": EXEC_REASON,
                "end_date": end_date, "end_input": end_input,
                "created_at": created_at, "created_by": build_user,
                "source_job": job_name, "source_build": build_url,
                "status": "draft", "hash": h
            }
            fj.write(json.dumps(rec, ensure_ascii=False) + "\n")
            cw.writerow([
                rid, seq, ns, wl, str(ex247).lower(), str(exow).lower(),
                EXEC_REQUESTER, EXEC_REASON, end_date, end_input, created_at, build_user,
                job_name, build_url, "draft", h
            ])

    dbg("‚úÖ Draft created in workspace:")
    dbg(f" - {out_jsonl}")
    dbg(f" - {out_csv}")

    # Retention
    if safe_path_guard(RAW_ROOT):
        retention_cleanup(RAW_ROOT, RETAIN_DAYS, RETENTION_DRY_RUN)
    else:
        dbg("‚ö†Ô∏è  B·ªè qua retention: RAW_ROOT kh√¥ng an to√†n.")

    # Publish
    day_dir = os.path.join(RAW_ROOT, datetime.date.today().isoformat())
    ensure_dir(day_dir)

    out_raw_jsonl = os.path.join(day_dir, f"raw-{rid}-{build_number}.jsonl")
    out_raw_csv   = os.path.join(day_dir, f"raw-{rid}-{build_number}.csv")
    tmp_jsonl     = out_raw_jsonl + ".tmp"
    tmp_csv       = out_raw_csv + ".tmp"

    shutil.copyfile(out_jsonl, tmp_jsonl); os.replace(tmp_jsonl, out_raw_jsonl)
    shutil.copyfile(out_csv,   tmp_csv);   os.replace(tmp_csv,   out_raw_csv)

    meta_path = os.path.join(day_dir, f"raw-{rid}-{build_number}.meta")
    with open(meta_path, "w", encoding="utf-8") as fm:
        fm.write(f"created_at={created_at}\n")
        fm.write(f"created_by={build_user}\n")
        fm.write(f"job={job_name}\n")
        fm.write(f"build={build_url}\n")
        fm.write(f"files={os.path.basename(out_raw_jsonl)},{os.path.basename(out_raw_csv)}\n")

    dbg("üì¶ Published:")
    dbg(f" - {out_raw_jsonl}")
    dbg(f" - {out_raw_csv}")
    dbg(f" - {meta_path}")
    try:
        print("\n=== Content of", out_raw_csv, "===\n")
        with open(out_raw_csv, "r", encoding="utf-8") as f:
            for line in f:
                print(line.rstrip())
        print("=== End of", out_raw_csv, "===\n")
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c {out_raw_csv}: {e}")
if __name__ == "__main__":
    main()
